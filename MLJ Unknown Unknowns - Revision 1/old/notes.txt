Notes for a next paper on Beat the Machine
from 1/23/12 discussion
----------------------------

So the plan is to define UUs starting by defining Known Unknowns and
presenting the sort of reject inference framework.  The picture should
show the UUs down in the corner, and the KUs in the center -- and
thereby far away from each other.  This also will highlight the fact
that the UUs are this errors in the estimated probability of class
membership (or cost, for 3b), which leads to our three red points (on
Panos's board).

What we should do is to push the cost-sensitive reject inference aside
for the purpose of the paper, and say that it certainly is important,
but that we can disuss everything that's relevant/that we need to
cover in the cost insensitive case, and the extensions to the
cost-sensitive case should be direct.

So now we've defined the UUs by the red stuff there (?), and we can
give some demonstrations perhaps.

Once we realize that this is a problem (UUs), we realize that we need
to evaluate classifiers not only by their generalization performance,
because assessments of g.p. make the closed-world assumption (that's
one reason), but also because of bad costs.

UUs vs accuracy (chart).  Examples on simulated data can show that
different models could give you different characteristic performance
(between UUs and generalization perf.).

A huge thing that's missing is still this open world problem.  The
fact that cases are not in your data could be because they simply are
rare (which could be a big problem if the costs are really skewed).
But they also could be missing because of the sampling process.  You
can't always assume that the data are a completely random sample from
the world or from the production environment.  Often the data actually
are some sort of convenience sample, despite the best efforts of the
data scientists.  So they may not include certain kinds of cases, and
if they're not there in the data, just about everything that we've
learned from KDD/ML/etc. falls apart.  It all makes this closed world
assumption.  (Thanks to Eric H.)

Is there something we can do?

We're saying yes.  We can take advantage of humans, and their own
insight and creativity, and borrow some language from teh guided
learning paper maybe.

So we offer the design and implementation of a system to *find*
unknown unknowns, taking advantage of humans.  We emphasize that this
is real data from a real problem using real classifiers, and real
people with a real crowd-sourcing system.  And we should that they in
fact find unknown unknown.  In the discussion section we may say
"would we have gotten better performance with different learning?"  We
could hold out some of the newly gotten UUs, and show real curves with
different learning systems (like linear vs. kNN or vs. the linear/kNN
hybrid) and see whether the curves actually cross.  If so, then it
shows that different models are different, depending on how you value
closed-world generalization performance estimates vs. open-world UU
performance.
