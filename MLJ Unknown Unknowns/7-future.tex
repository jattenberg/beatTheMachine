\section{Current and Future Research}

\panos{Perhaps we should also point that the system is 
implemented at AdSafe and also point to an open source version of the system, available at buildaclassifier.com. This may satisfy the infusion characteristic}

We presented the problem of ``unknown unknowns'' in the setting of predictive modeling and explored the design of the \emph{Beat the Machine} process for directly integrating humans into testing automatic decision models for vulnerabilities. Our results suggest that BTM is especially good in identifying cases where the model fails, while being confident that it is correct.  It is naturally interesting to examine how to best use knowledge of such vulnerabilities to improve the automatic decisions models. 


Vulnerability testing is common in areas of computer security, where ``white hat'' hackers with the appropriate expertise try to expose vulnerabilities in the security infrastructure of a firm. In our setting, we see that even lay users can easily find unknown holes in automatic decision models that test very well in ``standard'' tests, and show high classification performance when measured with the traditional, usual metrics (accuracy, AUC, etc).  Thus, builders of automatic decision models should take extra care when using these
traditional metrics for evaluations.

In our live deployment, untrained humans, with the appropriate incentives, were able to ``beat the machine'' seemingly easily, and discover a large number of vulnerabilities. This is, of course, useful by itself: the ``unknown unknowns'' become ``known unknowns'' and we can prepare to deal with these cases. But the key question for future research is also: how can we best incorporate such knowledge so that both ``unknown unknowns'' and ``known unknowns'' become ``known knowns.'' It turns out that building predictive models in the BTM setting is a very complicated problem. For example, oversampling cases where a model makes big mistakes can be catastrophic for  learning (think simply about oversampling outliers in a linear regression). On the other hand, techniques like boosting~\cite{Freund99ashort} have gotten tremendous advantage by overweighting cases where the current model is incorrect, and may aid future work. However, the benefit of being able to simultaneously explore a model's unknowns and offer robust model improvement make taking on such challenges worth while.

% \section*{Acknowledgements}

% The authors thank George A. Kellner and NEC for faculty fellowships,
% and AdSafe Media for expertise, support, and data.  The models used in
% this paper are not necessarily models used in production by any
% company. 


% [Add ambiguity in target variable to Limitations]

% ***To add to current/future work below:

%- How can we actually improve models with these unknown unknown cases?
%  Just plunking them into a training set yields mixed results.  This
%  may be because the training gets skewed, and we need to have a
%  specially designed training system.  Or it may be because we do not
%  really know how to evaluate the ``improved'' system.  What should be
%  the composition of the test set exactly?

%- In KDD-2010 we introduced guided learning, and showed that it can be
%  very useful for quickly building models in domains such as this.  We
%  are in the process of performing a similar comparison of BTM to GL.
%  Notably, GL also is not focused at all on the hard-to-envision
%  cases; in contrast, the incentive system there is to give easy to
%  find cases.

% For discussion:

% - relate to scenario planning
% - relate to white-hat hackers
