\section{Conclusion and Future Work}
\label{sec:conclusion}

% \panos{Perhaps we should also point that the system is 
% implemented at AdSafe and also point to an open source 
% version of the system, available at buildaclassifier.com. 
% This may satisfy the infusion requirement}

We presented the problem of unknown unknowns in the setting of predictive modeling and explored the design of the Beat the Machine process for directly integrating humans into testing automatic decision models for severe vulnerabilities. Our results suggest that BTM is especially good in identifying cases where the model fails, while being confident that it is correct.   Several companies have implemented systems based on the ideas of Beat the Machine, based directly on preliminary reports of this research.

% The BTM process, through its game-like structure and probing nature, encourages the discovery of unknown problems in the model. The fact that humans can easily find challenging cases for the automatic models, when being themselves confronted with this challenge, also indicates that human expertise and curiosity can improve even very accurate automatic models---and should be integrated more broadly into the evaluation of model-based systems. 

We believe that machine learning research should devote more study to this sort of system.  Presumably, even though we have gone through several design iterations, there is a lot to learn about how to design such systems to work well.  As we discussed in the deployment section, in addition to using BTM proper, companies already have been using the ideas in ways slightly different from the exact design we've presented. 
Furture, it is naturally interesting to ask how to best use knowledge of such vulnerabilities to improve the automatic decisions models.  To our knowledge, no work has yet studied this.  Our preliminary experiments indicate that building predictive models in the BTM setting is a very complicated problem. For example, oversampling cases where a model makes big mistakes can be catastrophic for  learning (think simply about oversampling outliers in a linear regression). On the other hand, techniques like boosting~\cite{Freund99ashort} have gotten tremendous advantage by overweighting cases where the current model is incorrect. The potential benefit of being able to simultaneously explore a model's unknowns and offer robust model improvement would be an exciting advance.






% Vulnerability testing is common in areas of computer security, where ``white hat'' hackers with the appropriate expertise try to expose vulnerabilities in the security infrastructure of a firm. In our setting, we see that even lay users can easily find unknown holes in automatic decision models that test very well in ``standard'' tests, and show high classification performance when measured with the traditional, usual metrics (accuracy, AUC, etc).  Thus, builders of automatic decision models should take extra care when using these
% traditional metrics for evaluations.

% In our live deployment, untrained humans, with the appropriate incentives, were able to ``beat the machine'' seemingly easily, and discover a large number of vulnerabilities. This is, of course, useful by itself: the ``unknown unknowns'' become ``known unknowns'' and we can prepare to deal with these cases. But the key question for future research is also: how can we best incorporate such knowledge so that both ``unknown unknowns'' and ``known unknowns'' become ``known knowns.''

% \section*{Acknowledgements}

% The authors thank George A. Kellner and NEC for faculty fellowships,
% and AdSafe Media for expertise, support, and data.  The models used in
% this paper are not necessarily models used in production by any
% company. 


% [Add ambiguity in target variable to Limitations]

% ***To add to current/future work below:

%- How can we actually improve models with these unknown unknown cases?
%  Just plunking them into a training set yields mixed results.  This
%  may be because the training gets skewed, and we need to have a
%  specially designed training system.  Or it may be because we do not
%  really know how to evaluate the ``improved'' system.  What should be
%  the composition of the test set exactly?

%- In KDD-2010 we introduced guided learning, and showed that it can be
%  very useful for quickly building models in domains such as this.  We
%  are in the process of performing a similar comparison of BTM to GL.
%  Notably, GL also is not focused at all on the hard-to-envision
%  cases; in contrast, the incentive system there is to give easy to
%  find cases.

% For discussion:

% - relate to scenario planning
% - relate to white-hat hackers
